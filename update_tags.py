import json
import csv
from collections import defaultdict

def enrich_tags_from_rankings(json_file_path, csv_file_path, output_csv_path):
    """
    æ ¹æ®JSONæ¦œå•æ–‡ä»¶ï¼Œæ‰©å……æˆ–æ›´æ–°CSVä¸­çš„å…¬å¸æ ‡ç­¾ã€‚

    Args:
        json_file_path (str): æ ‡å‡†åŒ–åçš„æ¦œå•JSONæ–‡ä»¶è·¯å¾„ã€‚
        csv_file_path (str): åŸå§‹çš„â€œæ ‡ç­¾å_å…¬å¸å.csvâ€æ–‡ä»¶è·¯å¾„ã€‚
        output_csv_path (str): æ›´æ–°åè¾“å‡ºçš„æ–°CSVæ–‡ä»¶è·¯å¾„ã€‚
    """
    
    # ==============================================================================
    # æ­¥éª¤ 1: å°†åŸå§‹CSVåŠ è½½åˆ°å†…å­˜ä¸­çš„é«˜æ•ˆæ•°æ®ç»“æ„ä¸­
    # ä½¿ç”¨ defaultdict(set)ï¼Œé”®æ˜¯å…¬å¸åï¼Œå€¼æ˜¯è¯¥å…¬å¸çš„æ ‡ç­¾é›†åˆ
    # ==============================================================================
    company_tags_db = defaultdict(set)
    
    print(f"æ­£åœ¨ä» '{csv_file_path}' åŠ è½½åŸå§‹æ ‡ç­¾æ•°æ®...")
    try:
        with open(csv_file_path, mode='r', encoding='utf-8-sig') as f:
            reader = csv.reader(f)
            # å°è¯•è¯»å–è¡¨å¤´
            try:
                header = next(reader)
                if header != ["æ ‡ç­¾å", "å…¬å¸å"]:
                    print(f"âš ï¸ è­¦å‘Š: CSVæ–‡ä»¶è¡¨å¤´ä¸æ˜¯é¢„æœŸçš„ ['æ ‡ç­¾å', 'å…¬å¸å']ï¼Œè€Œæ˜¯ {header}ã€‚")
                    # å°†ç¬¬ä¸€è¡Œä¹Ÿä½œä¸ºæ•°æ®å¤„ç†
                    if len(header) == 2:
                        tag, company = header[0].strip(), header[1].strip()
                        if tag and company:
                            company_tags_db[company].add(tag)
            except StopIteration:
                print("â„¹ï¸  ä¿¡æ¯: CSVæ–‡ä»¶ä¸ºç©ºæˆ–åªæœ‰ä¸€è¡Œã€‚")

            for row in reader:
                if len(row) < 2: continue
                tag, company = row[0].strip(), row[1].strip()
                if tag and company:
                    company_tags_db[company].add(tag)
        print(f"âœ… åŸå§‹æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(company_tags_db)} å®¶å…¬å¸çš„æ ‡ç­¾ã€‚")
    except FileNotFoundError:
        print(f"â„¹ï¸  ä¿¡æ¯: åŸå§‹æ ‡ç­¾æ–‡ä»¶ '{csv_file_path}' ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºä¸€ä¸ªå…¨æ–°çš„æ–‡ä»¶ã€‚")
    except Exception as e:
        print(f"âŒ ä¸¥é‡é”™è¯¯: è¯»å–CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return

    # ==============================================================================
    # æ­¥éª¤ 2: åŠ è½½å¹¶éå†JSONæ¦œå•æ–‡ä»¶ï¼Œæ›´æ–°å†…å­˜ä¸­çš„æ•°æ®åº“
    # ==============================================================================
    print(f"\næ­£åœ¨ä» '{json_file_path}' è¯»å–æ¦œå•ä¿¡æ¯è¿›è¡Œæ‰©å……...")
    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            rankings_data = json.load(f)
    except FileNotFoundError:
        print(f"âŒ ä¸¥é‡é”™è¯¯: æ¦œå•æ–‡ä»¶ '{json_file_path}' æœªæ‰¾åˆ°ï¼")
        return
    except json.JSONDecodeError:
        print(f"âŒ ä¸¥é‡é”™è¯¯: æ¦œå•æ–‡ä»¶ '{json_file_path}' ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚")
        return
    
    update_count = 0
    new_entry_count = 0
    
    # éå†æ¯ä¸ªæ¦œå•
    for ranking_name, company_list in rankings_data.items():
        ranking_name = ranking_name.strip()
        if not ranking_name: continue # è·³è¿‡ç©ºçš„æ¦œå•å
        

        # éå†æ¦œå•ä¸‹çš„æ¯ä¸ªå…¬å¸
        for company_name in company_list:
            company_name = company_name.strip()
            if not company_name: continue # è·³è¿‡ç©ºçš„å…¬å¸å

            # 1. è®°å½•å…¬å¸åœ¨æ·»åŠ æ–°æ ‡ç­¾å‰çš„å­˜åœ¨çŠ¶æ€
            # æ£€æŸ¥ company_name æ˜¯å¦å·²ç»åœ¨ company_tags_db ä¸­
            company_existed_before_add = company_name in company_tags_db
            
            # 2. å°è¯•å°†æ¦œå•åæ·»åŠ åˆ°å…¬å¸çš„æ ‡ç­¾é›†åˆä¸­
            # å¦‚æœ ranking_name å·²ç»å­˜åœ¨äºè¯¥å…¬å¸çš„æ ‡ç­¾é›†åˆä¸­ï¼Œset.add() ä¸ä¼šåšä»»ä½•æ”¹å˜
            # å¦‚æœ ranking_name ä¸å­˜åœ¨ï¼Œset.add() ä¼šæ·»åŠ å®ƒ
            
            # ä¸ºäº†ç²¾ç¡®åˆ¤æ–­æ˜¯å¦æ˜¯â€œæ–°çš„æ ‡ç­¾æ·»åŠ è¡Œä¸ºâ€ï¼Œæˆ‘ä»¬å…ˆè·å–å½“å‰æ ‡ç­¾æ•°é‡
            initial_tag_count = len(company_tags_db[company_name]) # defaultdictä¼šåœ¨æ­¤å¤„ä¸ºæ–°å…¬å¸åˆ›å»ºç©ºé›†åˆ

            company_tags_db[company_name].add(ranking_name)
            
            # 3. æ ¹æ®æ ‡ç­¾æ•°é‡æ˜¯å¦å¢åŠ æ¥æ›´æ–°è®¡æ•°å™¨
            # åªæœ‰å½“å®é™…æ·»åŠ äº†æ–°çš„æ¦œå•æ ‡ç­¾æ—¶ï¼Œæ‰æ›´æ–°è®¡æ•°
            if len(company_tags_db[company_name]) > initial_tag_count:
                if company_existed_before_add:
                    update_count += 1 # å…¬å¸å·²å­˜åœ¨ï¼Œä¸”æ·»åŠ äº†ä¸€ä¸ªæ–°æ ‡ç­¾
                else:
                    new_entry_count += 1 # å…¬å¸æ˜¯æ–°æ·»åŠ çš„ï¼Œä¸”æ¦œå•æ˜¯å®ƒçš„ç¬¬ä¸€ä¸ªæ ‡ç­¾
    
    print("âœ… æ ‡ç­¾æ•°æ®æ‰©å……å®Œæˆï¼")

    # ==============================================================================
    # æ­¥éª¤ 3: å°†æ›´æ–°åçš„å†…å­˜æ•°æ®åº“å†™å›æ–°çš„CSVæ–‡ä»¶
    # ==============================================================================
    print(f"\næ­£åœ¨å°†æ›´æ–°åçš„æ•°æ®å†™å…¥åˆ° '{output_csv_path}'...")
    try:
        with open(output_csv_path, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            # å†™å…¥è¡¨å¤´
            writer.writerow(['æ ‡ç­¾å', 'å…¬å¸å'])
            
            # ä¸ºäº†è¾“å‡ºæ–‡ä»¶æ›´è§„æ•´ï¼ŒæŒ‰å…¬å¸åæ’åº
            sorted_companies = sorted(company_tags_db.keys())
            
            # éå†æ¯ä¸ªå…¬å¸
            for company in sorted_companies:
                # è·å–è¯¥å…¬å¸çš„æ‰€æœ‰æ ‡ç­¾ï¼Œå¹¶æ’åº
                tags = sorted(list(company_tags_db[company]))
                # å°†æ‰€æœ‰æ ‡ç­¾ç”¨é€—å·è¿æ¥æˆä¸€ä¸ªå­—ç¬¦ä¸²
                tags_str = ','.join(tags)
                # å†™å…¥ä¸€è¡Œ
                writer.writerow([tags_str, company])
                
        print("\n--- ä»»åŠ¡æ€»ç»“ ---")
        print(f"æ›´æ–°äº† {update_count} å®¶å·²æœ‰å…¬å¸çš„æ ‡ç­¾ã€‚")
        print(f"æ–°å¢äº† {new_entry_count} å®¶å…¬å¸çš„æ¡ç›®ã€‚")
        print(f"æœ€ç»ˆæ•°æ®åº“åŒ…å« {len(company_tags_db)} å®¶å…¬å¸çš„æ ‡ç­¾ä¿¡æ¯ã€‚")
        print(f"ğŸ‰  æ‰€æœ‰æ•°æ®å·²æˆåŠŸå†™å…¥åˆ°: '{output_csv_path}'")

    except Exception as e:
        print(f"ğŸ”¥  ä¸¥é‡é”™è¯¯: æ— æ³•å°†æ•°æ®å†™å…¥åˆ° '{output_csv_path}': {e}")


if __name__ == '__main__':
    # --- é…ç½®åŒº ---
    # è¾“å…¥æ–‡ä»¶
    json_rankings_file = 'normalized_rankings.json'
    csv_tags_file = 'æ ‡ç­¾å_å…¬å¸å.csv'
    
    # è¾“å‡ºæ–‡ä»¶ (ä½¿ç”¨æ–°åå­—ä»¥é¿å…è¦†ç›–åŸå§‹æ–‡ä»¶)
    output_csv_file = 'æ ‡ç­¾å_å…¬å¸å_updated.csv'
    
    # --- è¿è¡Œä¸»å‡½æ•° ---
    enrich_tags_from_rankings(json_rankings_file, csv_tags_file, output_csv_file)