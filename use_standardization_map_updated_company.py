import csv

def build_standardization_map(rules_csv_path):
    """
    Args:
        rules_csv_path (str): 'company_clusters_review.csv' çš„è·¯å¾„ã€‚

    Returns:
        dict: ä¸€ä¸ªæ˜ å°„å­—å…¸ï¼Œä¾‹å¦‚ {'æµ·å°”é›†å›¢å…¬å¸': 'æµ·å°”é›†å›¢å…¬å¸', 'åˆ«å2': 'æ ‡å‡†å'}
    """
    name_map = {}
    print(f"æ­£åœ¨ä» '{rules_csv_path}' æ„å»ºæ ‡å‡†åŒ–è§„åˆ™æ˜ å°„...")
    try:
        with open(rules_csv_path, mode='r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            
            for row in reader:
                # è·å–æ ‡å‡†åï¼ˆæˆ‘ä»¬å†³ç­–åçš„ 'last' åˆ—ï¼‰
                standard_name = row.get('last', '').strip()
                if not standard_name:
                    continue # å¦‚æœ 'last' åˆ—ä¸ºç©ºï¼Œåˆ™è·³è¿‡æ­¤è§„åˆ™

                # è·å–æ‰€æœ‰éœ€è¦è¢«æ›¿æ¢çš„åˆ«å
                # 1. 'Standard_Name_Suggestion' åˆ—æœ¬èº«æ˜¯ä¸€ä¸ªåˆ«å
                suggestion_alias = row.get('Standard_Name_Suggestion', '').strip()
                if suggestion_alias:
                    name_map[suggestion_alias] = standard_name

                # 2. 'Aliases_Found' åˆ—å¯èƒ½åŒ…å«å¤šä¸ªç”± ' | ' åˆ†éš”çš„åˆ«å
                aliases_str = row.get('Aliases_Found', '').strip()
                if aliases_str:
                    aliases_list = [alias.strip() for alias in aliases_str.split(' | ')]
                    for alias in aliases_list:
                        if alias:
                            name_map[alias] = standard_name
        
        print(f"âœ… æ ‡å‡†åŒ–è§„åˆ™æ˜ å°„æ„å»ºå®Œæˆï¼Œå…±åŒ…å« {len(name_map)} æ¡æ›¿æ¢è§„åˆ™ã€‚")
        return name_map

    except FileNotFoundError:
        print(f"âŒ ä¸¥é‡é”™è¯¯: è§„åˆ™æ–‡ä»¶ '{rules_csv_path}' æœªæ‰¾åˆ°ï¼è¯·æ£€æŸ¥æ–‡ä»¶åå’Œè·¯å¾„ã€‚")
        return None
    except Exception as e:
        print(f"âŒ ä¸¥é‡é”™è¯¯: è¯»å–è§„åˆ™æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return None

def standardize_company_names(data_csv_path, name_map, output_csv_path):
    """
    éå†æ•°æ®æ–‡ä»¶ï¼Œä½¿ç”¨æ˜ å°„å­—å…¸è¿›è¡Œå…¬å¸åæ ‡å‡†åŒ–ã€‚

    Args:
        data_csv_path (str): 'æ ‡ç­¾å_å…¬å¸å_updated.csv' çš„è·¯å¾„ã€‚
        name_map (dict): æ ‡å‡†åŒ–è§„åˆ™çš„æ˜ å°„å­—å…¸ã€‚
        output_csv_path (str): æœ€ç»ˆè¾“å‡ºæ–‡ä»¶çš„è·¯å¾„ã€‚
    """
    print(f"\næ­£åœ¨å¯¹ '{data_csv_path}' ä¸­çš„å…¬å¸åè¿›è¡Œæ ‡å‡†åŒ–...")
    
    # ä½¿ç”¨withè¯­å¥åŒæ—¶æ‰“å¼€è¯»å†™æ–‡ä»¶
    try:
        with open(data_csv_path, 'r', encoding='utf-8-sig') as infile, \
             open(output_csv_path, 'w', newline='', encoding='utf-8-sig') as outfile:
            
            reader = csv.reader(infile)
            writer = csv.writer(outfile)
            
            # è¯»å–å¹¶å†™å…¥è¡¨å¤´
            header = next(reader)
            writer.writerow(header)
            
            processed_count = 0
            replaced_count = 0

            # é€è¡Œå¤„ç†æ•°æ®
            for row in reader:
                if len(row) < 2: continue
                
                tags, original_company_name = row[0], row[1].strip()
                
                # æ ¸å¿ƒé€»è¾‘ï¼šä½¿ç”¨ .get() æ–¹æ³•è¿›è¡ŒæŸ¥æ‰¾å’Œæ›¿æ¢
                # å¦‚æœåœ¨mapä¸­æ‰¾åˆ°ï¼Œåˆ™è¿”å›æ ‡å‡†åï¼›å¦‚æœæ‰¾ä¸åˆ°ï¼Œåˆ™è¿”å›åŸå§‹åç§°æœ¬èº«ã€‚
                standardized_name = name_map.get(original_company_name, original_company_name)
                
                # æ£€æŸ¥æ˜¯å¦å‘ç”Ÿäº†æ›¿æ¢ï¼Œå¹¶è®¡æ•°
                if standardized_name != original_company_name:
                    replaced_count += 1
                
                # å†™å…¥æ–°çš„ä¸€è¡Œ
                writer.writerow([tags, standardized_name])
                processed_count += 1
            
            print("\n--- æ ‡å‡†åŒ–ä»»åŠ¡æ€»ç»“ ---")
            print(f"æ€»å…±å¤„ç†äº† {processed_count} è¡Œæ•°æ®ã€‚")
            print(f"æˆåŠŸæ›¿æ¢äº† {replaced_count} ä¸ªå…¬å¸åä¸ºæ ‡å‡†åç§°ã€‚")
            print(f"ğŸ‰  æœ€ç»ˆçš„æ ‡å‡†åŒ–æ•°æ®å·²æˆåŠŸå†™å…¥åˆ°: '{output_csv_path}'")

    except FileNotFoundError:
        print(f"âŒ ä¸¥é‡é”™è¯¯: æ•°æ®æ–‡ä»¶ '{data_csv_path}' æœªæ‰¾åˆ°ï¼")
    except Exception as e:
        print(f"âŒ ä¸¥é‡é”™è¯¯: å¤„ç†æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == '__main__':
    # --- é…ç½®åŒº ---
    # è¾“å…¥æ–‡ä»¶
    # è¿™æ˜¯æ‚¨äººå·¥å†³ç­–åçš„è§„åˆ™æ–‡ä»¶
    rules_file = 'tag_clusters_review.csv' 
    # è¿™æ˜¯å¾…å¤„ç†çš„æ•°æ®æ–‡ä»¶
    data_file = 'æ ‡ç­¾å_å…¬å¸å_final.csv'
    
    # è¾“å‡ºæ–‡ä»¶
    # è¿™æ˜¯æœ€ç»ˆçš„ã€å¹²å‡€çš„æ•°æ®æ–‡ä»¶
    final_output_file = 'æ ‡ç­¾å_å…¬å¸å_final_v2.csv'
    
    # --- è¿è¡Œä¸»æµç¨‹ ---
    # 1. æ„å»ºè§„åˆ™æ˜ å°„
    standardization_rules = build_standardization_map(rules_file)
    
    # 2. å¦‚æœè§„åˆ™æ„å»ºæˆåŠŸï¼Œåˆ™åº”ç”¨è§„åˆ™
    if standardization_rules:
        standardize_company_names(data_file, standardization_rules, final_output_file)