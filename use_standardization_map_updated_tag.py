import csv

def build_standardization_map(rules_csv_path):
    """
    æ ¹æ®è§„åˆ™æ–‡ä»¶æ„å»ºä¸€ä¸ªä»åˆ«ååˆ°æ ‡å‡†åçš„æ˜ å°„å­—å…¸ã€‚

    Args:
        rules_csv_path (str): åŒ…å«æ ‡ç­¾æ ‡å‡†åŒ–è§„åˆ™çš„CSVæ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ 'tag_clusters_review.csv'ã€‚

    Returns:
        dict: ä¸€ä¸ªæ˜ å°„å­—å…¸ï¼Œä¾‹å¦‚ {'æ—§æ ‡ç­¾åˆ«å': 'æ ‡å‡†æ ‡ç­¾å', 'åˆ«å2': 'æ ‡å‡†æ ‡ç­¾å'}
    """
    tag_map = {}
    print(f"æ­£åœ¨ä» '{rules_csv_path}' æ„å»ºæ ‡ç­¾æ ‡å‡†åŒ–è§„åˆ™æ˜ å°„...")
    try:
        with open(rules_csv_path, mode='r', encoding='utf-8-sig') as f:
            # ä½¿ç”¨ DictReader å¯ä»¥æ–¹ä¾¿åœ°é€šè¿‡åˆ—åè®¿é—®æ•°æ®
            reader = csv.DictReader(f)
            
            for row in reader:
                # è·å–æ ‡å‡†åï¼ˆæˆ‘ä»¬å†³ç­–åçš„ 'last' åˆ—ï¼‰
                standard_name = row.get('last', '').strip()
                if not standard_name:
                    continue # å¦‚æœ 'last' åˆ—ä¸ºç©ºï¼Œåˆ™è·³è¿‡æ­¤è§„åˆ™

                # è·å–æ‰€æœ‰éœ€è¦è¢«æ›¿æ¢çš„åˆ«å
                # 1. 'Standard_Name_Suggestion' åˆ—æœ¬èº«æ˜¯ä¸€ä¸ªåˆ«å
                suggestion_alias = row.get('Standard_Name_Suggestion', '').strip()
                if suggestion_alias:
                    tag_map[suggestion_alias] = standard_name

                # 2. 'Aliases_Found' åˆ—å¯èƒ½åŒ…å«å¤šä¸ªç”± ' | ' åˆ†éš”çš„åˆ«å
                aliases_str = row.get('Aliases_Found', '').strip()
                if aliases_str:
                    aliases_list = [alias.strip() for alias in aliases_str.split(' | ')]
                    for alias in aliases_list:
                        if alias:
                            tag_map[alias] = standard_name
        
        print(f"âœ… æ ‡ç­¾æ ‡å‡†åŒ–è§„åˆ™æ˜ å°„æ„å»ºå®Œæˆï¼Œå…±åŒ…å« {len(tag_map)} æ¡æ›¿æ¢è§„åˆ™ã€‚")
        return tag_map

    except FileNotFoundError:
        print(f"âŒ ä¸¥é‡é”™è¯¯: è§„åˆ™æ–‡ä»¶ '{rules_csv_path}' æœªæ‰¾åˆ°ï¼è¯·æ£€æŸ¥æ–‡ä»¶åå’Œè·¯å¾„ã€‚")
        return None
    except Exception as e:
        print(f"âŒ ä¸¥é‡é”™è¯¯: è¯»å–è§„åˆ™æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return None

def standardize_tag_names(data_csv_path, tag_map, output_csv_path):
    """
    éå†æ•°æ®æ–‡ä»¶ï¼Œä½¿ç”¨æ˜ å°„å­—å…¸è¿›è¡Œæ ‡ç­¾åæ ‡å‡†åŒ–ã€‚

    Args:
        data_csv_path (str): å¾…å¤„ç†çš„æ•°æ®æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ 'æ ‡ç­¾å_å…¬å¸å_final.csv'ã€‚
        tag_map (dict): æ ‡ç­¾æ ‡å‡†åŒ–è§„åˆ™çš„æ˜ å°„å­—å…¸ã€‚
        output_csv_path (str): æœ€ç»ˆè¾“å‡ºæ–‡ä»¶çš„è·¯å¾„ã€‚
    """
    print(f"\næ­£åœ¨å¯¹ '{data_csv_path}' ä¸­çš„æ ‡ç­¾åè¿›è¡Œæ ‡å‡†åŒ–...")
    
    try:
        with open(data_csv_path, 'r', encoding='utf-8-sig') as infile, \
             open(output_csv_path, 'w', newline='', encoding='utf-8-sig') as outfile:
            
            reader = csv.reader(infile)
            writer = csv.writer(outfile)
            
            # è¯»å–å¹¶å†™å…¥è¡¨å¤´
            header = next(reader)
            writer.writerow(header)
            
            processed_count = 0
            replaced_count = 0

            # é€è¡Œå¤„ç†æ•°æ®
            for row in reader:
                if len(row) < 2: continue # ç¡®ä¿è¡Œè‡³å°‘æœ‰ä¸¤åˆ—
                
                # è¯»å–åŸå§‹çš„æ ‡ç­¾åå’Œå…¬å¸å
                original_tag_name = row[0].strip()
                company_name = row[1].strip()
                
                # æ ¸å¿ƒé€»è¾‘ï¼šåœ¨æ˜ å°„å­—å…¸ä¸­æŸ¥æ‰¾åŸå§‹æ ‡ç­¾åã€‚
                # å¦‚æœæ‰¾åˆ°ï¼Œåˆ™è¿”å›æ ‡å‡†æ ‡ç­¾åï¼›å¦‚æœæ‰¾ä¸åˆ°ï¼Œåˆ™è¿”å›åŸå§‹æ ‡ç­¾åæœ¬èº«ã€‚
                standardized_tag_name = tag_map.get(original_tag_name, original_tag_name)
                
                # æ£€æŸ¥æ˜¯å¦å‘ç”Ÿäº†æ›¿æ¢ï¼Œå¹¶è®¡æ•°
                if standardized_tag_name != original_tag_name:
                    replaced_count += 1
                
                # å°†ã€æ ‡å‡†åŒ–åçš„æ ‡ç­¾åã€‘å’Œã€åŸå§‹å…¬å¸åã€‘å†™å…¥æ–°æ–‡ä»¶
                writer.writerow([standardized_tag_name, company_name])
                processed_count += 1
            
            print("\n--- æ ‡å‡†åŒ–ä»»åŠ¡æ€»ç»“ ---")
            print(f"æ€»å…±å¤„ç†äº† {processed_count} è¡Œæ•°æ®ã€‚")
            print(f"æˆåŠŸæ›¿æ¢äº† {replaced_count} ä¸ªæ ‡ç­¾åä¸ºæ ‡å‡†åç§°ã€‚")
            print(f"ğŸ‰ æœ€ç»ˆçš„æ ‡å‡†åŒ–æ•°æ®å·²æˆåŠŸå†™å…¥åˆ°: '{output_csv_path}'")

    except FileNotFoundError:
        print(f"âŒ ä¸¥é‡é”™è¯¯: æ•°æ®æ–‡ä»¶ '{data_csv_path}' æœªæ‰¾åˆ°ï¼")
    except Exception as e:
        print(f"âŒ ä¸¥é‡é”™è¯¯: å¤„ç†æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == '__main__':
    # --- é…ç½®åŒº ---
    # è¾“å…¥æ–‡ä»¶
    # è¿™æ˜¯æ‚¨äººå·¥å†³ç­–åçš„æ ‡ç­¾è§„åˆ™æ–‡ä»¶
    rules_file = 'tag_clusters_review.csv' 
    # è¿™æ˜¯å¾…å¤„ç†çš„æ•°æ®æ–‡ä»¶
    data_file = 'æ ‡ç­¾å_å…¬å¸å_final.csv'
    
    # è¾“å‡ºæ–‡ä»¶
    # è¿™æ˜¯æœ€ç»ˆçš„ã€å¹²å‡€çš„æ•°æ®æ–‡ä»¶
    final_output_file = 'æ ‡ç­¾å_å…¬å¸å_final_v1.csv'
    
    # --- è¿è¡Œä¸»æµç¨‹ ---
    # 1. æ„å»ºæ ‡ç­¾æ ‡å‡†åŒ–è§„åˆ™æ˜ å°„
    standardization_rules = build_standardization_map(rules_file)
    
    # 2. å¦‚æœè§„åˆ™æ„å»ºæˆåŠŸï¼Œåˆ™åº”ç”¨è§„åˆ™è¿›è¡Œæ ‡ç­¾æ ‡å‡†åŒ–
    if standardization_rules:
        standardize_tag_names(data_file, standardization_rules, final_output_file)